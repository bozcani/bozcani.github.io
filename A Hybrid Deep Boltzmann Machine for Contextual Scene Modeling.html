<!DOCTYPE html>
<!-- saved from url=(0031)http://sscnet.cs.princeton.edu/ -->
<html><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
	<title>A Hybrid Deep Boltzmann Machine for Contextual Scene Modeling</title>
	<link rel="stylesheet" type="text/css" href="./A Hybrid Deep Boltzmann Machine for Contextual Scene Modeling_files/pvg.css">
</head>
<body>
<div><a href="http://www.kovan.ceng.metu.edu.tr/" target="_self"><img src="./A Hybrid Deep Boltzmann Machine for Contextual Scene Modeling_files/kovan_logo_yan.png" style="margin-top: 5px;" height="80px" width="289px"></a>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; <div class="icon"><a href="http://www.kovan.ceng.metu.edu.tr/"><img src="./A Hybrid Deep Boltzmann Machine for Contextual Scene Modeling_files/home.svg">Home</a></div><div class="icon"><a href="http://www.kovan.ceng.metu.edu.tr/index.php/Research"><img src="./A Hybrid Deep Boltzmann Machine for Contextual Scene Modeling_files/research.svg">Research</a></div><div class="icon"><a href="http://www.kovan.ceng.metu.edu.tr/index.php/Publications"><img src="./A Hybrid Deep Boltzmann Machine for Contextual Scene Modeling_files/publications.svg">Publications</a></div><div class="icon"><a href="http://www.kovan.ceng.metu.edu.tr/index.php/Members"><img src="./A Hybrid Deep Boltzmann Machine for Contextual Scene Modeling_files/people.svg">People</a></div></div>


<table width="85%" border="0" align="center" cellpadding="0" cellspacing="0" style="margin-top: 30px;">
  <tbody><tr> 
    <td> 



<h1 align="center" style="font-size: 18pt;"><b>A Hybrid Deep Boltzmann Machine for Contextual Scene Modeling</b></h1><br>

<center><img src="./A Hybrid Deep Boltzmann Machine for Contextual Scene Modeling_files/overview.png" style="width: 100%;"> <figcaption>(a) An overview of the proposed hybrid tri-way
Boltzmann Machine, where the tri-way edges are shown in red, and (b) some examples for what it can provide to a robot</figcaption> </center>

<h2>Abstract</h2>
<p>
Scene models allow robots to reason about what is in the scene, what else should be in it, and what
should not be in it. In this paper, we propose a hybrid Boltzmann Machine (BM) for scene modeling
where relations between objects are integrated. To be able to do that, we extend BM to include tri-
way edges between visible (object) nodes and make the network to share the relations across
different objects. We evaluate our method against several baseline models (Deep Boltzmann
Machines, and Restricted Boltzmann Machines) on a scene classification dataset, and show that it
performs better in several scene reasoning tasks.
</p>

<h2>Paper</h2>

<ul>
İlker Bozcan, Yağmur Oymak, İdil Zeynep Alemdar, Sinan Kalkan <br>
<b>What is (missing or wrong) in the scene? A Hybrid Deep Boltzmann Machine For Contextualized Scene Modeling</b> (<b> ICRA 2018 </b>) <br>
<a href=""> [paper] </a> <a href=""> [bibtex] </a>  <a href=""> [code] </a> 
<a href=""> [poster] </a> <a href=""> [talk] </a> <a href=""> [slides] </a> 
</ul>

<!-- <h2>Bibtex</h2>
<ul>

</ul> -->


<h2>Method & Results</h2>
<p>
We propose a triway deep BM for scene modeling. Visible nodes are separated into two groups:
relations(r) and objects(v). Relation nodes(visible) are shared between two object nodes. Visible
nodes(both of relation and visible nodes) are connected to units at the first hidden layer. Hidden
layers are stacked to make model deep.
</p>

<p>
Gibbs sampling is used for inference instead of variational inference since our dataset is relatively
small (total 3485 samples) and input vectors are too sparse (i.e. slight number of relation nodes are
active). It is a type of Monte Carlo Markov Chain Method that can guarantee precise inferences.
Precise inference is important for our problem since only slight number of relation nodes are active
for each sample.
</p>

<p>
We conduct several experiments that includes scenarios that can be performed by robots in real
world problems. We compared our model’s results(Triway BM) with Restricted Boltzmann
Machine(RBM) and General Boltzmann Machine(GBM) that is structured as bidirectional links
exists within input layer and hidden layers are stacked.
</p>

<p>
The first experiment is estimation of relations between objects that are on the scene for current
context. In this experiment, firstly, model determines context by using objects on the scene only,
then using by context and activation of objects, it estimates relations among objects on the scene.
For this task, we define accuracy as the percentage of relations correctly estimated with respect
to the labeled relations in the test dataset. We see that our model provides highest accuracy(Table 1).

<style type="text/css">
.tg  {border-collapse:collapse;border-spacing:0;}
.tg td{font-family:Arial, sans-serif;font-size:14px;padding:10px 5px;border-style:solid;border-width:1px;overflow:hidden;word-break:normal;}
.tg th{font-family:Arial, sans-serif;font-size:14px;font-weight:normal;padding:10px 5px;border-style:solid;border-width:1px;overflow:hidden;word-break:normal;}
.tg .tg-g145{font-family:"Times New Roman", Times, serif !important;;text-align:center;vertical-align:top}
.tg .tg-s2f6{font-family:"Times New Roman", Times, serif !important;;text-align:center}
</style>
<center>
<table class="tg">
  <tr>
    <th class="tg-g145">RBM</th>
    <th class="tg-g145">GBM</th>
    <th class="tg-g145">Triway BM</th>
    <th class="tg-g145">Chance level</th>
  </tr>
  <tr>
    <td class="tg-g145">12.06%</td>
    <td class="tg-g145">14.18%</td>
    <td class="tg-g145">23.35%</td>
    <td class="tg-g145">1.4310^-4%</td>
  </tr>
<subcaption>Table 1: Performance (accuracy) of the methods on estimating relations between a given set of
objects. Higher is better.</subcaption>
</table>
</center>
</p>




<p>
The second experiment is finding missing object(s) on the scene according to current context. In
this task, we randomly de-activate an object from the scene and expect the network to find the
missing object. For this task, we define accuracy as the percentage of the missing objects found
correctly in the test dataset. Our model is the best(Table 2).


<center>
<table class="tg">
  <tr>
    <th class="tg-g145">RBM</th>
    <th class="tg-g145">GBM</th>
    <th class="tg-g145">Triway BM</th>
    <th class="tg-g145">Chance level</th>
  </tr>
  <tr>
    <td class="tg-g145">35.12%</td>
    <td class="tg-g145">40.94%</td>
    <td class="tg-g145">43.28%</td>
    <td class="tg-g145">5.75*10^*6%</td>
  </tr>
<subcaption>Table 2: Performance (accuracy) of the methods on finding missing object in the scene. Higher is
better.</subcaption>
</table>
</center>
</p>

<p>
The third experiment is finding the objects that are out of current context on the scene. For this task,
we select scenes, remove randomly an object and add randomly another object not in the scene. We
define error measure to indicate how much reconstructed data is different form original data that is
without extra objects. Our model is the best(Table 3).
<center>
<table class="tg">
  <tr>
    <th class="tg-g145">RBM</th>
    <th class="tg-g145">GBM</th>
    <th class="tg-g145">Triway BM</th>
    <th class="tg-g145">Chance level</th>
  </tr>
  <tr>
    <td class="tg-g145">0.6446</td>
    <td class="tg-g145">0.1404</td>
    <td class="tg-g145">0.0789</td>
    <td class="tg-g145">0.5</td>
  </tr>
<subcaption>Table 3: Performance (error) of the methods on finding what is out of context in the scene. Lower is
better.</subcaption>
</table>
</center>
</p>



<p>
The last experiment is random scene generation. In this task, we randomly activate hidden units and
visible units are sampled according to context that is determined by hidden units.
</p>


         


<!-- <h2>Code</h2>
<ul>
Coming soon ...
</ul> -->

<h2>Video</h2>

<center>
<iframe width="853" height="480" src="https://www.youtube.com/embed/c3LTPQNLnBI" frameborder="0" allowfullscreen=""></iframe>
</center>
<br>


<div style="text-align: center; width: 100%; margin-top: 25px; "><p style="color: #999; font-size: 9pt; ">© <script>document.write(new Date().getFullYear())</script> KOVAN Research Labs ‒ <a href="http://www.ceng.metu.edu.tr/" style="color:#EE7F2D;">Department of Computer Engineering</a> @ <a href="http://www.metu.edu.tr/" style="color:#EE7F2D;">Middle East Technical University</a> ‒ Üniversiteler Mahallesi, 
Dumlupınar Bulvarı No:1
06800 Çankaya Ankara/TÜRKİYE.</p></div>

</td></tr></tbody></table></body></html>
